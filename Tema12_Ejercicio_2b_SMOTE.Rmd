---
title: "Tema12_Ejercicio_2b_SMOTE"
author: "Fran Camacho"
date: "2025-05-05"
output: html_document
---

# Tema 12 - Ejercicio 2

Utilizando el archivo Bank.csv del Tema 7, reequilibre la muestra utilizando
SMOTE y repita el ejercicio usando la técnica que desee (redes neuronales
o SVM), comparando los resultados obtenidos con los que se obtuvieron
previamente.

```{r}
#https://www.jstatsoft.org/article/view/v011i09
if (!require(kernlab)) install.packages('kernlab', dependencies = T)
library(kernlab) 

if (!require(tidyverse)) install.packages('tidyverse', dependencies = T)
library(tidyverse)

if (!require(caret)) install.packages('caret', dependencies = T)
library(caret)

# themis contains extra steps for the recipes package for dealing with unbalanced data. 
if (!require(themis)) install.packages('themis', dependencies = T)
library(themis)
```



## Carga de los datos


Cargamos mismos datos que en el ejercicio 7. 


```{r}
# import the CSV file
bank_raw <- read.csv(file.path("CSVs/Bank", "bank.csv"), sep = ";", stringsAsFactors = TRUE)
```


Se trataba de un dataset con un gran desequilibrio en la variable dependiente:

```{r}
#table(bank_raw$y)
fct_count(bank_raw$y, prop = TRUE)
```


## Aplicando SMOTE (Synthetic Minority Oversampling Technique)

En esta versión "B" vamos a aplicar SMOTE solo sobre los conjuntos de entrenamiento y validación.
El conjunto de test lo separamos antes de aplicar esta técnica.

Por supuesto el procesado (normalización, hot encoding ..), sí se aplica a todo el dataset:

```{r}
#scale numeric variables (neither day nor month)
maxs <- apply(bank_raw[c(1,6,12,13,14,15)], 2, max)
mins <- apply(bank_raw[c(1,6,12,13,14,15)], 2, min)

bank_norm <- data.frame(scale(bank_raw[c(1,6,12,13,14,15)], center = mins, scale = maxs - mins))

#hot encoding of categorical features         
dummies <- dummyVars(" ~ job + marital + education + default + housing + loan + contact + poutcome", data = bank_raw)
bank_hot_encoded_feat <-  data.frame(predict(dummies, newdata = bank_raw))

#encoding month (name to number)
month_to_number <- function(month_name) {
  month_and_number <- c("jan"=1,"feb"=2,"mar"=3,"apr"=4,"may"=5,"jun"=6,"jul"=7,"aug"=8,"sep"=9,"oct"=10,"nov"=11,"dec"=12)
  return(month_and_number[as.character(month_name)])
}
bank_raw$month_num <- sapply(bank_raw$month, month_to_number)


#put all features in the same dataframe
bank_processed <- cbind(bank_norm,as.numeric(bank_raw$day),bank_raw$month_num,bank_hot_encoded_feat,bank_raw$y)
names(bank_processed)[7:8] <- c("day","month")
names(bank_processed)[41] <- "y"
head(bank_processed,5)

```

Creamos los conjuntos de entrenamiento y test:

```{r}
#Set seed to make the process reproducible
set.seed(9)

#partitioning data frame into training (75%) and testing (25%) sets
train_indices <- createDataPartition(bank_processed$y, times=1, p=.75, list=FALSE)

#create training set
bank_processed_train <- bank_processed[train_indices, ]

#create testing set
bank_processed_test  <- bank_processed[-train_indices, ]


#view number of rows in each set
nrow(bank_processed_train)  # 3391
nrow(bank_processed_test)   # 1130

```

Las proporciones se mantienen evidentemente:
 
```{r}
fct_count(bank_processed_train$y, prop = TRUE)
fct_count(bank_processed_test$y, prop = TRUE)
```


### SMOTE

Ahora se aplica la función smote() de la librería themis al conjunto de entrenamiento:

```{r}
#library(themis)
bank_processed_train_balanced <- bank_processed_train |> smote("y")  # using y as the feature to balance

fct_count(bank_processed_train_balanced$y, prop = TRUE)
```
Y como se ve queda balanceado.

```{r, fig.height=8}
boxplot(bank_raw$balance, main = "Boxplot of Balance", ylab = "Balance")

boxplot(bank_processed_train_balanced$balance, main = "Boxplot of Balance (SMOTE)", ylab = "Balance")
```



## Ahora que ya tenemos el dataset balanceado, aplicamos SVM:


Entrenamiento 1:

La idea es obtener unos primeros valores sobre los que iterar en el entrenamiento 2.

```{r}
ctrl_accu <- trainControl(method = "cv", number = 10, selectionFunction = "best", 
                     classProbs=TRUE)
```

```{r}
set.seed(12345)

system.time({
  m_accu <- train(y ~ ., data = bank_processed_train_balanced, method = "svmRadial",
            metric = "Accuracy",
            trControl = ctrl_accu)
})
```


```{r}
cat("Using Accuracy:\n")
m_accu
```

Anteriormente (tema 12 ejercicio "a"):

  C     Accuracy   Kappa    
  0.25  0.8841667  0.7683333
  0.50  0.8958333  0.7916667
  1.00  0.9061111  0.8122222

Tuning parameter 'sigma' was held constant at a value of 0.01712261
Accuracy was used to select the optimal model using the largest value.
The final values used for the model were sigma = 0.01712261 and C = 1.


Así que en principio tiene buena pinta ...


```{r}
plot(m_accu)
```


Entrenamiento 2:

```{r}
grid_2 <- expand.grid(C = c(1, 5, 10, 20),
                    sigma = c(0.015, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.15))
grid_2
```


```{r}
set.seed(12345)

system.time({
  m_accu_2 <- train(y ~ ., data = bank_processed_train_balanced, method = "svmRadial",
            metric = "Accuracy",
            trControl = ctrl_accu,
            tuneGrid = grid_2)
})
```

```{r}
set.seed(12345)

system.time({
  m_kappa_2 <- train(y ~ ., data = bank_processed_train_balanced, method = "svmRadial",
            metric = "Kappa",
            trControl = ctrl_accu,
            tuneGrid = grid_2)
})
```


```{r}
cat("Using Accuracy:\n")
m_accu_2
```
Accuracy was used to select the optimal model using the largest value.
The final values used for the model were sigma = 0.15 and C = 5.

 C  sigma  Accuracy   Kappa
 5  0.150  0.9695000  0.9390000


```{r}
cat("Using Kappa:\n")
m_kappa_2
```

Kappa was used to select the optimal model using the largest value.
The final values used for the model were sigma = 0.15 and C = 5.

  C  sigma  Accuracy   Kappa    
  5  0.150  0.9695000  0.9390000

Se obtiene el mismo valor que usando la exactitud ....


```{r}
plot(m_accu_2)
```

```{r}
plot(m_kappa_2)
```

```{r}
m_accu_2$finalModel
```

```{r}
m_kappa_2$finalModel
```


Finalmente, realizamos la predicción y la evaluación usando el dataset que habíamos reservado para test:

Hay que recordar que este dataset no está balanceado, lo reservamos antes de aplicar SMOTE.
(La idea es simular datos nuevos, reales):

```{r}
fct_count(bank_processed_test$y, prop = TRUE)
```


Predicción:

```{r}

m_accu_pred <- predict(m_accu_2, bank_processed_test[,1:40])

```

```{r}

m_kappa_pred <- predict(m_kappa_2, bank_processed_test[,1:40])

```

Matriz de confusión:

```{r}
confusionMatrix(ref = as.factor(bank_processed_test$y), data = as.factor(m_accu_pred), positive="yes", mode = "everything")
```
```{r}
confusionMatrix(ref = as.factor(bank_processed_test$y), data = as.factor(m_kappa_pred), positive="yes", mode = "everything")
```





Algunos enlaces con info. sobre SMOTE:


https://datascience.stackexchange.com/questions/106461/why-smote-is-not-used-in-prize-winning-kaggle-solutions


https://www.youtube.com/watch?v=6YnhoCfArQo

(captura del minuto 3:43 - guardada en el escritorio)

https://trainindata.substack.com/p/to-smote-or-not-to-smote

"The one thing I criticize about this article, is that they applied ordinal encoding to categorical data, and then, 
SMOTE will create values that are not possible. If category blue is encoded as 1 and category red is encoded as 2, 
then a value created by SMOTE could be 2.3, what would that be? Purple? You get me."



