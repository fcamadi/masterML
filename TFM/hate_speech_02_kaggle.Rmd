---
title: "hate_speech_02"
author: "Fran Camacho"
date: "2025-06-04"
output: word_document
---


# TFM - Procesar dataset kaggle - SVM


```{r}
source('hate_speech_common.R')
```


Carga de paquetes que son necesarios para diversas funciones.

```{r}
load_libraries()    
```



# Paso 1: obtención del dataset y procesado preliminar


```{r}
# import the CSV file
odio_kaggle_raw <- read.csv(file.path("source_datasets/dataset_03_kaggle.csv"), sep=";")  
odio_kaggle_raw <- odio_kaggle_raw[-1]       # -> 11180 obs. (only spanish) of 2 variables
``` 



Estructura del dataset:

```{r}
str(odio_kaggle_raw)
```


La columna "label" es de tipo int. Ya que se trata en realidad de una variable categórica 0/1, es conveniente transformarla en un factor:

```{r}
#Convert class into a factor
odio_kaggle_raw$label <- factor(odio_kaggle_raw$label)
```


Examinamos el resultado

```{r}
table(odio_kaggle_raw$label)
prop.table(table(odio_kaggle_raw$label))
```

Este dataset está desbalanceado, pero no de una manera tan exagerada como los otros.


```{r}
head(odio_kaggle_raw)
```

```{r}
tail(odio_kaggle_raw)
```


# Paso 2: procesado del dataset


Como primer paso, se van a eliminar las referencias a otros usuarios en los comentarios. 

También, con ayuda de la librería cleantext examinamos los comentarios y haremos un primer procesado:

```{r}
#check_text(odio_kaggle_raw$post)  #omitted for brevity

odio_kaggle <- preprocess_posts(odio_kaggle, odio_kaggle_raw)
```


Comprobamos el resultado:

```{r}
odio_kaggle[1:5,1]

#check_text(odio_kaggle$post)
```


### Corpus

Creación del objeto corpus con todas los mensajes:

```{r}
#create corpus
posts_corpus <- VCorpus(VectorSource(odio_kaggle$post))
print(posts_corpus)
```


Limpieza de los textos del corpus:

```{r}
system.time({

  posts_corpus_clean <- clean_corpus(posts_corpus)

})
```


Se examina el corpus y no se aprecia nada raro.

```{r}
#View(posts_corpus_clean)
```


Finalmente se procede a la **"tokenización"** de los comentarios. Se obtiene una DTM:

```{r}
system.time({
  posts_dtm <- DocumentTermMatrix(posts_corpus_clean)
})

posts_dtm
```


Ahora hay que crear los conjuntos de entrenamiento y de test.


Dado que este dataset ya viene separado en dos conjuntos así, lo que hacemos es cargar el dataset de test:


```{r}
# import the CSV file
odio_kaggle_test_raw <- read.csv(file.path("source_datasets/dataset_04_kaggle.csv"), sep=";")  # -> 1243 obs. (only spanish) of 3 variables
odio_kaggle_test_raw <- odio_kaggle_test_raw[-1]
```



Lo procesamos de igual manera que el de entrenamiento:


```{r}
#Convert class into a factor
odio_kaggle_test_raw$label <- factor(odio_kaggle_test_raw$label)

#process df test
odio_kaggle_test <- preprocess_posts(odio_kaggle_test, odio_kaggle_test_raw)
```


```{r}
#create corpus test
posts_test_corpus <- VCorpus(VectorSource(odio_kaggle_test$post))
print(posts_test_corpus)
```

Limpieza del corpus de test también:

```{r}
system.time({

  posts_corpus_test_clean <- clean_corpus(posts_test_corpus)

})
```

Tokenización:

```{r}
posts_dtm_test <- DocumentTermMatrix(posts_corpus_test_clean)
```



Se necesita ahora obtener un listado con las palabras más utilizadas:


```{r}
# Data preparation – creating indicator features for frequent words
# the function findFreqTerms() in the tm package takes a DTM and returns a character vector containing words that appear at least a  minimum number of times
posts_freq_words_train <- findFreqTerms(posts_dtm, 50)

#posts_freq_words_train
print("tonto" %in% posts_freq_words_train)    
print("imbecil" %in% posts_freq_words_train)  # <- TRUE with freq 100
print("cabron" %in% posts_freq_words_train)   # <- FALSE with freq 150
```

   [1] "¿cómo"           "¿por"            "¿que"            "¿qué"            "¿te"             "abajo"           "abierta"         "abr"            
   [9] "absoluta"        "abuela"          "abuelo"          "abuso"           "acá"             "acaba"           "acabar"          "acabo"          
  [17] "acaso"           "ácido"           "acoso"           "acto"            "acuerdo"         "acusacion"       "acusado"         "ademá"          
  [25] "adversario"      "aficion"         "afición"         "africano"        "agent"           "agresión"        "agua"            "aguantar"       
  [33] "ahi"             "ahí"             "ahora"           "ahr"             "alegro"          "aleman"          "alemania"        "algo"      
  ...
  985] "propio"          "provocar"        "prueba"          "psoe"            "pública"         "público"         "pue"             "pueblo"         
 [993] "pued"            "pueda"           "pueden"          "puedo"           "puerta"          "puesto"          "puigdemont"      "punto"          
 [ reached 'max' / getOption("max.print") -- omitted 344 entries ]




Y ahora utilizamos ese listado para limitar el número de columnas/features tanto del conjuntos de entrenamiento como del de test:

```{r}
dim(posts_dtm)
posts_dtm_freq_train <- posts_dtm[ , posts_freq_words_train]
dim(posts_dtm_freq_train)

dim(posts_dtm_test)
posts_dtm_freq_test <- posts_dtm_test[ , posts_freq_words_train]     
dim(posts_dtm_freq_test)

```


## Paso 3: Entrenamiento del modelo


Tanto caret como LIBSVM (e1071) han demostrado ser muy poco eficientes a la hora de tratar dataset de estos tamaños.

Utilizamos por tanto LiblineaR también con este dataset.


```{r}
# dtm -> matrix

posts_freq_train_mat <- as.matrix(posts_dtm_freq_train)
#posts_freq_train_mat <- as(as(as(posts_freq_train_mat, "dMatrix"), "generalMatrix"), "RsparseMatrix")

posts_freq_test_mat <- as.matrix(posts_dtm_freq_test)
#posts_freq_test_mat <- as(as(as(posts_freq_test_mat, "dMatrix"), "generalMatrix"), "RsparseMatrix")
```



```{r}
system.time({

  liblinear_svm_model <- LiblineaR(data = posts_freq_train_mat, target = odio_kaggle$label, type = 3)  # C = 1, not the found with heuristicC

})
  
```


```{r}
# prediction
system.time({
  
  prediction_liblinear <- predict(liblinear_svm_model, posts_freq_test_mat)

})
```


```{r}
#Confusion matrix
confusionMatrix(reference = as.factor(odio_kaggle_test$label), data = as.factor(prediction_liblinear$predictions), positive="1", mode = "everything")
```

Coeficiente de correlacción de Matthews:

```{r}
# mcc -> Matthews correlation coefficient
mcc(as.factor(odio_kaggle_test$label), as.factor(prediction_liblinear$predictions))
```


Se obtiene el mismo resultado usando matrices densas y dispersas.
En este dataset, al ser de un tamaño pequeño, no hay problema en utilizar matrices densas.
(Y esto permite utilizar la función heurística)



- Intentamos mejorar el modelo usando el coste calculado por la función heurística:

Intentamos obtener un valor óptimo de coste con la función heuristicC, como aconsejan los creadores de esta librería.

```{r}
# For a sparse matrix not possible. And when the sparse matrix is huge, you cannot convert it to a dense matrix

c <- tryCatch({
  cost <- heuristicC(posts_freq_train_mat)
  cost
}, error = function(err) {
  # error handler
  print(paste("ERROR: ",err))
  1 #default cost
})
cat("c: ",c)
```


```{r}
system.time({
  liblinear_svm_model_c <- LiblineaR(data = posts_freq_train_mat, target = odio_kaggle$label, type = 3,  cost = 10) 
    
  prediction_liblinear_c <- predict(liblinear_svm_model_c, posts_freq_test_mat)
})
```

```{r}
confusionMatrix(reference = as.factor(odio_kaggle_test$label), data = as.factor(prediction_liblinear_c$predictions), positive="1", mode = "everything") 
```


Utilizando el coste calculado por la función heurística, el resultado es peor.
En cambio, eligiendo un coste por encima de 1 (1.5, 2, 3, 5 ..), se mejora el resultado. Elegimos el mejor coste = 10.



- Intentamos mejorar el modelo usando pesos, para favorecer la detección de la clase minoritaria:


```{r}
# Define class weights
class_weights <- c("0" = 2, "1" = 3)  # Assign higher weight to the minority class
```


```{r}
system.time({

  liblinear_svm_model_weights <- LiblineaR(data = posts_freq_train_mat, target = odio_kaggle$label, type = 3, cost = 1,
                                   wi = class_weights)
  
  prediction_liblinear_weights <- predict(liblinear_svm_model_weights, posts_freq_test_mat)
})
```


```{r}
#Confusion matrix
confusionMatrix(reference = as.factor(odio_kaggle_test$label), data = as.factor(prediction_liblinear_weights$predictions), positive="1", mode = "everything")
```

Coeficiente de correlacción de Matthews:

```{r}
# mcc -> Matthews correlation coefficient
mcc(as.factor(odio_kaggle_test$label), as.factor(prediction_liblinear_weights$predictions))
```



- Coste 1, pesos 1/3:

          Reference
Prediction   0   1
         0 496  88
         1 323 336
                                          
Accuracy : 0.6693          
   Kappa : 0.3511          
      F1 : 0.6205  


- Coste 10, pesos 1/3:

          Reference
Prediction   0   1
         0 490  83
         1 329 341
                                          
Accuracy : 0.6685          
   Kappa : 0.3531          
      F1 : 0.6234 


- Coste 1, pesos 2/3:

          Reference
Prediction   0   1
         0 666 145
         1 153 279
                                          
Accuracy : 0.7603          
   Kappa : 0.4691          
      F1 : 0.6519 


Probando diferentes combinaciones del parámetro coste y de los pesos, los mejores valores obtenidos rondan el 76-77% para la exactitud y un kappa del 0.47.





