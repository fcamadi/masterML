---
title: "hate_speech_01"
author: "Fran Camacho"
date: "2025-03-29"
output: word_document
---


# TFM - Preparar CSVs con los datasets originales.


En esta carpeta "TFM_Aux" se encuentras los datasets originales.

La función de este primer hate_speech_01.Rmd es explorar esos datasets sobre lenguaje de odio en español encontrados en internet,
y producir a partir de ellos unos .csv lo más uniformes posibles.


```{r}
print(getwd())
```


### 1 - Dataset obtenido del proyecto "Hatemedia"


https://hatemedia.es/

GitHub:

https://github.com/esaidh266/Hate-Speech-Library-in-Spanish

Dataset:  https://doi.org/10.6084/m9.figshare.26085700.v1

"El dataset que se ha utilizado para el entrenamiento de los modelos de algoritmos de odio/no odio, intensidad y tipo. 
El datasets consta de mensajes (noticias y comentarios), publicados por en usuarios asociados a El Mundo, ABC, La Vanguardia, 
El Mundo y 20 Minutos en Twitter y sus portales webs, durante el mes de enero de 2021."

Este dataset está ya parcialmente procesado (eliminadas "stopwords" ...)

```{r}
# import the hatemedia csv file
odio_hatemedia_raw <- read.csv(file.path("source_datasets/dataset_completo_v1.csv"), sep=";")  # -> 574272 obs. of 22 variables

# In a linux console: 
# head -n 200001 dataset_completo_v1.csv > dataset_200k.csv 
#odio_hatemedia_raw <- read.csv(file.path("dataset_100k.csv"), sep=";")
```

```{r}
head(odio_hatemedia_raw)
```


```{r}
str(odio_hatemedia_raw)
```

Solo se necesitan las columnas "comentario" y "label"

```{r}
odio_hatemedia_raw <- odio_hatemedia_raw[,6:7]
```

Vemos la proporción de los mensajes:

```{r}
table(odio_hatemedia_raw$label)
```

Este dataset está muy muy desbalanceado como se puede ver.

Y parece que los mensajes de odio están todos al final del dataset:

```{r}
#which(odio_raw_coments_labels$label==1)
```

[1] 563209 563210 563211 563212 563213 563214 563215 563216 563217 563218 563219 563220
...
[991] 564199 564200 564201 564202 564203 564204 564205 564206 564207 564208
 [ reached 'max' / getOption("max.print") -- omitted 10064 entries ]
 


Renombramos las variables. Todos los datasets tendrán estos nombres:

```{r}
# Rename columns
colnames(odio_hatemedia_raw) <- c("post", "label")
```

Finalmente exportamos el dataset a un csv para tenerlo guardado.

```{r}
#export dataset to a file
write.csv2(odio_hatemedia_raw, "source_datasets/dataset_01_hatemedia.csv")
```

[

  Echamos un vistazo a los mensajes de odio, para ver qué aspecto tienen:

```{r}
odio <- odio_hatemedia_raw[odio_hatemedia_raw$label==1.0,]

head(odio$post)
```

]

### 2 - Dataset encontrado en HuggingFace


Se trata de un "superdataset" compuesto por varios datasets (2 de España, 2 de Chile y uno de México).

Nombre del fichero: es_hf_102024.csv

https://huggingface.co/datasets/manueltonneau/spanish-hate-speech-superset

"This dataset is a **superset (N=29,855)** of posts annotated as hateful or not. 
It results from the preprocessing and merge of all available Spanish hate speech datasets in April 2024."

[...]

The dataset contains six columns:
- text: the annotated post
- labels: annotation of whether the post is hateful (`== 1`) or not (`==0`). As datasets have different annotation schemes, we systematically binarized the labels.
- source: origin of the data (e.g., Twitter)
- dataset: dataset the data is from (see "Datasets" part below)
- nb_annotators`: number of annotators by post
- tweet_id: tweet ID where available
- post_author_country_location: post author country location, when it could be inferred. Details on the inference in [our survey paper](https://aclanthology.org/2024.woah-1.23/).

[...]

"The datasets that compose this superset are:

- hateEval, SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter (`hateval` in the `dataset` column)
  - [paper link](https://www.aclweb.org/anthology/S19-2007)
  - [raw data link](https://github.com/msang/hateval/tree/master)
- Detecting and Monitoring Hate Speech in Twitter (`haternet` in the `dataset` column)
  - [paper link](https://www.mdpi.com/1424-8220/19/21/4654)
  - [raw data link](https://zenodo.org/record/2592149#.XmuNJahKg2w)
- Multilingual Resources for Offensive Language Detection (`chileno`)
  - [paper link](https://aclanthology.org/2022.woah-1.pdf#page=136)
  - [raw data link](https://github.com/aymeam/Datasets-for-Hate-Speech-Detection/tree/master/Chilean%20dataset)
- Analyzing Zero-Shot transfer Scenarios across Spanish variants for Hate Speech Detection (`hascosva`)
  - [paper link](https://aclanthology.org/2023.vardial-1.1.pdf)
  - [raw data link](https://gitlab.inria.fr/counter/HaSCoSVa/-/blob/main/dataset/hascosva_2022_anonymized.tsv?ref_type=heads)
- HOMO-MEX: A Mexican Spanish Annotated Corpus for LGBT+phobia Detection on Twitter (`homomex`)
  - [paper link](https://aclanthology.org/2023.woah-1.20.pdf)
  - [raw data link](https://github.com/juanmvsa/HOMO-MEX)"
  
  

NOTA:
considerar solo los conjuntos hateval y haternet?
(Por no mezclar el español de España con el de México, Chile ...)

En principio los consideramos todos.

```{r}
# import the CSV file
odio_huggingface_raw <- read.csv(file.path("source_datasets/es_hf_102024.csv"))  # -> 29855 obs. of 7 variables
```

Estructura:

```{r}
str(odio_huggingface_raw)
```


Algunos registros:

```{r}
head(odio_huggingface_raw)
```

No se tiene en cuenta el dataset origen del comentario, ni ninguna otra información que no sea el comentario y su etiqueta:

```{r}
odio_huggingface_raw <- odio_huggingface_raw[,1:2]
```

```{r}
# Rename columns
colnames(odio_huggingface_raw) <- c("post", "label")
```


Está desbalanceado también, pero no de manera tan exagerada como el de Hatemedia:

```{r}
table(odio_huggingface_raw$label)
```

Los mensajes de odio están intercalados:

```{r}
#which(odio_huggingface_raw$label==1)
```
   [1]    3   24  106  142  143  161  164  177  179  193  203  2
   ...
   [973] 9874 9875 9876 9877 9878 9879 9880 9881 9882 9883 9884 9885 9886 9887 9888 9889 9890 9891 9892 9893 9894 9895 9896 9897 9898 9899 9900 9901
 [ reached 'max' / getOption("max.print") -- omitted 6265 entries ]
 


Lo escribimos también en un fichero:

```{r}
#export dataset to a file
write.csv2(odio_huggingface_raw, "source_datasets/dataset_02_huggingface.csv")
```


### 3 - Dataset encontrado en Kaggle

MultiLanguageTrainDataset.csv

https://www.kaggle.com/datasets/wajidhassanmoosa/multilingual-hatespeech-dataset

About Dataset:

This dataset contains hate speech text with labels where 0 represents non-hate and 1 shows hate
texts also the data from different languages needed to be identified as a corresponding
correct language. The following are the languages in the dataset with the numbers corresponding to that language.
(1 Arabic)(2 English)(3 Chinese)(4 French) (5 German) (6 Russian)(7 Turkish) (8 Roman Hindi/Urdu) (9 Korean)(10 Italian) (11 Spanish)(12 Portuguese) (13 Indonesian)


Leer fichero csv:

```{r}
# import the CSV file
odio_kaggle_raw <- read.csv(file.path("source_datasets/MultiLanguageTrainDataset.csv"))  # -> 219981 obs. (all languages) of 4 variables
```

Estructura:

```{r}
str(odio_kaggle_raw)
```

Lo primero que debemos hacer, es extraer de este "MultiLanguageTrainDataset" los mensajes en castellano:

```{r}
odio_kaggle_raw_ES <- odio_kaggle_raw[odio_kaggle_raw$language==11,2:3]
```

Examinar dataset:

```{r}
head(odio_kaggle_raw_ES)
```
Renombrar variables:

```{r}
# Rename columns
colnames(odio_kaggle_raw_ES) <- c("post", "label")
```


Este dataset también está desbalanceado, pero no de manera tan exagerada:

```{r}
table(odio_kaggle_raw_ES$label)
```

Los mensajes de odio están intercalados:

```{r}
#which(odio_kaggle_raw_ES$label==1)
```

 [1]    5    6    8    9   10   14   15   18   22   23   34   35   43   44
 ...
 [981] 2979 2980 2988 2996 3000 3001 3005 3007 3009 3011 3016 3018 3025 3030 3032 3046 3049 3050 3051 3056
 [ reached 'max' / getOption("max.print") -- omitted 2815 entries ]


Lo escribimos también en un fichero:

```{r}
#export dataset to a file
write.csv2(odio_kaggle_raw_ES, "source_datasets/dataset_03_kaggle.csv")
```



**Hacemos lo mismo con el dataset de test.**

Consieramos este dataset como entrenamiento también.

Luego se harán 3 grupos:  entrenamiento, validación, y test.


```{r}
# import the CSV file
odio_kaggle_raw_Test_ES <- read.csv(file.path("source_datasets/Spain_test.csv"))  # -> 1243 obs. (only spanish) of 3 variables
```

Estructura:

```{r}
str(odio_kaggle_raw_Test_ES)
```


Los mensajes de odio también están intercalados:

```{r}
odio_kaggle_raw_Test_ES <- odio_kaggle_raw_Test_ES[-1]
head(odio_kaggle_raw_Test_ES)
```
```{r}
which(odio_kaggle_raw_Test_ES$label==1)
```

Renombramos columnas:

```{r}
# Rename columns
colnames(odio_kaggle_raw_Test_ES) <- c("post", "label")
```


Lo escribimos también en un fichero:

```{r}
#export dataset to a file
write.csv2(odio_kaggle_raw_Test_ES, "source_datasets/dataset_04_kaggle.csv")
```


### CSVs:

El total de observaciones "raw" es:

```{r}
nrow(odio_hatemedia_raw)+nrow(odio_huggingface_raw)+nrow(odio_kaggle_raw_ES)+nrow(odio_kaggle_raw_Test_ES)
```


Todos los dataframes (y los CSVs obtenidos de ellos) tienen 2 columnas: "post" y "label".

El dataset de Hatemedia tiene una peculiaridad: el dataset obtenido ya había sido procesado en parte.
Ya se eliminaron las "stop words", los números ..

Creemos que se trata de una cantidad considerable de comentarios etiquetados para poder entrenar de manera adecuado al SVM.


### 4 - Mensajes de odio "sintéticos" producidos con LLMs

Se ha probado también a generar mensajes de odio usando varios LLMs.
Dado el número de mensajes etiquetados encontrados, no creo que estos mensajes "sintéticos" sean necesarios.



