---
title: "Tema11_Improve_NB_Model"
author: "Fran Camacho"
date: "2025-04-30"
output: word_document
---


# Tema 11 - Mejora de un modelo de ML usando la libreria caret

1. Utilizando el procedimiento descrito en el capítulo 11 del libro con la
librería caret, realice una búsqueda de los parámetros óptimos para
cualquiera de los modelos de las pruebas de evaluación de los temas 3, 4,
5, 6 o 7. Comente los resultados obtenidos.

Utilizaremos Naive Bayes como en el tema 4. 

Examinamos en la documentación los candidatos:

http://topepo.github.io/caret/available-models.html


Candidatos:

Model        method Vale   Type            Libraries   Tuning Paremeters   
--------------------------------------------------------------------------------
Naive Bayes	 naive_bayes	 Classification	 naivebayes	 laplace, usekernel, adjust

Naive Bayes	 nb	           Classification	 klaR	       fL, usekernel, adjust

Utilizaremos el método naive_bayes de la librería naivebayses, ya que esta librería es 
la que fue utilizada en el tema 4.


## Paso 1: Carga de los datos

```{r}
# import the CSV file
movies_raw <- read.csv(file.path("CSVs", "Movie_pang02.csv"))
```

## Paso 2: Preparación de los datos

Preparamos el dataset de igual manera a como lo hicimos en el ejercicio 4.

Carga de paquetes que son necesarios para diversas funciones.

```{r}
if (!require(tm)) install.packages('tm', dependencies = T) # text mining
library(tm)

if (!require(SnowballC)) install.packages('SnowballC', dependencies = T) # stemming
library(SnowballC)

#if (!require(naivebayes)) install.packages('naivebayes', dependencies = T)
#library(naivebayes)

if (!require(caret)) install.packages('caret', dependencies = T)
library(caret)         
```


```{r}
#See the structure
str(movies_raw)
```

La columna "class" es de tipo carácter. Ya que se trata en realidad de una variable categórica, la transformábamos en un factor:

```{r}
#Convert class into a factor
movies_raw$class <- factor(movies_raw$class)

table(movies_raw$class) # -> 1000 Neg, 1000 Pos
```

Se trataba de un dataset totalmente balanceado.

Procesado de los textos:

```{r}
#create corpus
movies_corpus <- VCorpus(VectorSource(movies_raw$text))
print(movies_corpus)

# Process the reviews (we will use some functions from the packate tm)
#
#To lowercase (content seems to be already in lowercase and without punctuation signs, but just in case)
movies_corpus_clean <- tm_map(movies_corpus, content_transformer(tolower))
#Remove numbers
movies_corpus_clean <- tm_map(movies_corpus_clean, removeNumbers)
#Remove stopwords
movies_corpus_clean <- tm_map(movies_corpus_clean, removeWords, stopwords()) 
#Remove punctuation signs
movies_corpus_clean <- tm_map(movies_corpus_clean, removePunctuation) 

#Carry out the stemming:
# To apply the wordStem() function to an entire corpus of text documents, the tm package includes
# the stemDocument() transformation.
movies_corpus_clean <- tm_map(movies_corpus_clean, stemDocument)

#Finally eliminate unneeded whitespace produced by previous steps
movies_corpus_clean <- tm_map(movies_corpus_clean, stripWhitespace) 

# Tokenization - document-term matrix (DTM)
movies_dtm <- DocumentTermMatrix(movies_corpus_clean)
movies_dtm
```

Volvemos a obtener 2000 documentos y 24951 términos.


Ahora hay que crear los conjuntos de entrenamiento y de test.
Las críticas vienen ordenadas, primero las 1000 críticas positivas, y después las 1000 críticas negativas.
Por tanto hay que crear estos dos conjuntos de manera aleatoria.

```{r}
#Set seed to make the process reproducible
set.seed(8)

#partitioning data frame into training (75%) and testing (25%) sets
train_indices <- createDataPartition(movies_raw$class, times=1, p=.75, list=FALSE)

#create training set
movies_dtm_train <- movies_dtm[train_indices, ]

#create testing set
movies_dtm_test  <- movies_dtm[-train_indices, ]

#create labels sets
movies_train_labels <- movies_raw[train_indices, ]$class
movies_test_labels <- movies_raw[-train_indices, ]$class

#view number of rows in each set
nrow(movies_dtm_train)  # 1500
nrow(movies_dtm_test)   # 500
length(movies_train_labels)  # 1500
length(movies_test_labels)   # 500
```

Volvemos a comprobar que los dos conjuntos tienen la misma proporción de críticas positivas y negativas (si no, el entrenamiento no serviría para nada):

```{r}
prop.table(table(movies_train_labels))
prop.table(table(movies_test_labels))
```

###Finalizamos la preparación de los datos

Se necesita obtener un listado con las palabras más utilizadas:

```{r}
# Data preparation – creating indicator features for frequent words
# the function findFreqTerms() in the tm package takes a DTM and returns a character vector containing words that appear at least a  minimum number of times
movies_freq_words <- findFreqTerms(movies_dtm_train, 100)

#movies_freq_words
```
  [1] "abil"         "abl"          "absolut"      "accept"       "achiev"       "across"       "act"          "action"       "actor"        "actress"      "actual"      
 [12] "adam"         "adapt"        "add"          "addit"        "admit"        "adult"        "adventur"     "age"          "agent"        "ago"          "agre"        
...
 [991] "whatev"       "whether"      "white"        "whole"        "whose"        "wife"         "wild"         "will"         "willi"        "william"     
 [ reached 'max' / getOption("max.print") -- omitted 27 entries ]


Y ahora utilizamos ese listado para limitar el número de columnas/features:

```{r}
ncol(movies_dtm_train)
#[1] 24951

movies_dtm_freq_train <- movies_dtm_train[ , movies_freq_words]
movies_dtm_freq_test <- movies_dtm_test[ , movies_freq_words]

ncol(movies_dtm_freq_train)
#[1] 1027
```


Finalmente, ya que las matrices DTM tienen valores numéricos, mientras que el algoritmo de clasificación basado en naive bayes necesita operar sobre variables categóricas, se necesita realizar una última tranformación: pasar los valores numéricos a Sí/No:

```{r}
convert_counts <- function(x) {
  factor(ifelse(x > 0, "Yes", "No"))  # IMPORTANTE: usar factor()
}

# Aplicamos la conversi?n y creamos data.frame
movies_train_df <- as.data.frame(apply(movies_dtm_freq_train, MARGIN = 2, convert_counts))
movies_train_df$class <- movies_train_labels  

movies_test_df <- as.data.frame(apply(movies_dtm_freq_test, MARGIN = 2, convert_counts))

# Verificamos estructura
str(movies_train_df[1:5])
```


## Uso de caret para mejorar el modelo

Para comprobar qué parámetros pueden ser ajustados:

```{r}
modelLookup("naive_bayes")
```

Objeto control:

```{r}
ctrl <- trainControl(method = "cv", 
                     number = 10, 
                     selectionFunction = "best",
                     classProbs = TRUE,  
                     summaryFunction = twoClassSummary   # -> metric ROC in grid
                     ) 
```


Matriz de parámetros:

Intentamos que la matriz tenga un rango amplio de valores.

```{r}
grid <- expand.grid(
  laplace = c(0, 0.5, 1.0, 2.0, 10),
  usekernel = c(FALSE, TRUE),
  adjust = c(0.1, 0.5, 0.75, 1.0, 1.25, 1.5, 10, 50)
)
```


Entrenamiento:

```{r}
set.seed(12345)

system.time({
  
  m <- train(class ~ ., data = movies_train_df, 
                method = "naive_bayes",
                metric = "ROC",
                trControl = ctrl,
                tuneGrid = grid)
  
})
```


```{r}
print(m)
```




```{r}
plot(m)
```



```{r}
m$finalModel
```


Predicción:

```{r}
movies_pred <- predict(m, movies_test_df)
```



Resultado:

```{r}
#confusion matrix
confusionMatrix(reference = movies_test_labels, data = movies_pred, mode = "everything", positive = "Pos")
```


Se obtiene un resultado ligeramente peor que en la tarea del tema 4.



Resultado obtenido en el tema 4 con la librería naivebayes:

Confusion Matrix and Statistics

          Reference
Prediction Neg Pos
       Neg 207  59
       Pos  43 191
                                         
               Accuracy : 0.796          
                 95% CI : (0.758, 0.8305)
    No Information Rate : 0.5            
    P-Value [Acc > NIR] : <2e-16         
                                         
                  Kappa : 0.592          
                                         
 Mcnemar's Test P-Value : 0.1375         
                                         
            Sensitivity : 0.7640         
            Specificity : 0.8280         
         Pos Pred Value : 0.8162         
         Neg Pred Value : 0.7782         
              Precision : 0.8162         
                 Recall : 0.7640         
                     F1 : 0.7893         
             Prevalence : 0.5000         
         Detection Rate : 0.3820         
   Detection Prevalence : 0.4680         
      Balanced Accuracy : 0.7960         
                                         
       'Positive' Class : Pos   