---
title: "Tema11_Improve_NB_Model"
author: "Fran Camacho"
date: "2025-04-30"
output: word_document
---


# Tema 11 - Mejora de un modelo de ML usando la libreria caret

1. Utilizando el procedimiento descrito en el capítulo 11 del libro con la
librería caret, realice una búsqueda de los parámetros óptimos para
cualquiera de los modelos de las pruebas de evaluación de los temas 3, 4,
5, 6 o 7. Comente los resultados obtenidos.

Utilizaremos Naive Bayes como en el tema 4. 

Examinamos en la documentación los candidatos:

http://topepo.github.io/caret/available-models.html

Candidatos:

Model        method Vale   Type            Libraries   Tuning Paremeters   
--------------------------------------------------------------------------------
Naive Bayes	 naive_bayes	 Classification	 naivebayes	 laplace, usekernel, adjust

Naive Bayes	 nb	           Classification	 klaR	       fL, usekernel, adjust



## Paso 1: Carga de los datos

```{r}
# import the CSV file
movies_raw <- read.csv(file.path("CSVs", "Movie_pang02.csv"))
```

## Paso 2: Preparación de los datos

Preparamos el dataset de igual manera a como lo hicimos en el ejercicio 4.

Carga de paquetes que son necesarios para diversas funciones.

```{r}
if (!require(tm)) install.packages('tm', dependencies = T) # text mining
library(tm)

if (!require(SnowballC)) install.packages('SnowballC', dependencies = T) # stemming
library(SnowballC)

if (!require(naivebayes)) install.packages('naivebayes', dependencies = T)
library(naivebayes)

if (!require(caret)) install.packages('caret', dependencies = T)
library(caret)         
```


```{r}
#See the structure
str(movies_raw)
```

La columna "class" es de tipo carácter. Ya que se trata en realidad de una variable categórica, la transformábamos en un factor:

```{r}
#Convert class into a factor
movies_raw$class <- factor(movies_raw$class)

table(movies_raw$class) # -> 1000 Neg, 1000 Pos
```

Se trataba de un dataset totalmente balanceado.

Procesado de los textos:

```{r}
#create corpus
movies_corpus <- VCorpus(VectorSource(movies_raw$text))
print(movies_corpus)

# Process the reviews (we will use some functions from the packate tm)
#
#To lowercase (content seems to be already in lowercase and without punctuation signs, but just in case)
movies_corpus_clean <- tm_map(movies_corpus, content_transformer(tolower))
#Remove numbers
movies_corpus_clean <- tm_map(movies_corpus_clean, removeNumbers)
#Remove stopwords
movies_corpus_clean <- tm_map(movies_corpus_clean, removeWords, stopwords()) 
#Remove punctuation signs
movies_corpus_clean <- tm_map(movies_corpus_clean, removePunctuation) 

#Carry out the stemming:
# To apply the wordStem() function to an entire corpus of text documents, the tm package includes
# the stemDocument() transformation.
movies_corpus_clean <- tm_map(movies_corpus_clean, stemDocument)

#Finally eliminate unneeded whitespace produced by previous steps
movies_corpus_clean <- tm_map(movies_corpus_clean, stripWhitespace) 

# Tokenization - document-term matrix (DTM)
movies_dtm <- DocumentTermMatrix(movies_corpus_clean)
movies_dtm
```

Volvemos a obtener 2000 documentos y 24951 palabras.


Ahora hay que crear los conjuntos de entrenamiento y de test.
Las críticas vienen ordenadas, primero las 1000 críticas positivas, y después las 1000 críticas negativas.
Por tanto hay que crear estos dos conjuntos de manera aleatoria.

```{r}
#Set seed to make the process reproducible
set.seed(8)

#partitioning data frame into training (75%) and testing (25%) sets
train_indices <- createDataPartition(movies_raw$class, times=1, p=.75, list=FALSE)

#create training set
movies_dtm_train <- movies_dtm[train_indices, ]

#create testing set
movies_dtm_test  <- movies_dtm[-train_indices, ]

#create labels sets
movies_train_labels <- movies_raw[train_indices, ]$class
movies_test_labels <- movies_raw[-train_indices, ]$class

#view number of rows in each set
nrow(movies_dtm_train)  # 1500
nrow(movies_dtm_test)   # 500
length(movies_train_labels)  # 1500
length(movies_test_labels)   # 500
```

Volvemos a comprobar que los dos conjuntos tienen la misma proporción de críticas positivas y negativas (si no, el entrenamiento no serviría para nada):

```{r}
prop.table(table(movies_train_labels))
prop.table(table(movies_test_labels))
```

###Finalizamos la preparación de los datos

Se necesita obtener un listado con las palabras más utilizadas:

```{r}
# Data preparation – creating indicator features for frequent words
# the function findFreqTerms() in the tm package takes a DTM and returns a character vector containing words that appear at least a  minimum number of times
movies_freq_words <- findFreqTerms(movies_dtm_train, 100)

movies_freq_words
```
  [1] "abil"         "abl"          "absolut"      "accept"       "achiev"       "across"       "act"          "action"       "actor"        "actress"      "actual"      
 [12] "adam"         "adapt"        "add"          "addit"        "admit"        "adult"        "adventur"     "age"          "agent"        "ago"          "agre"        
...
 [991] "whatev"       "whether"      "white"        "whole"        "whose"        "wife"         "wild"         "will"         "willi"        "william"     
 [ reached 'max' / getOption("max.print") -- omitted 27 entries ]


Y ahora utilizamos ese listado para limitar el número de columnas/features:

```{r}
ncol(movies_dtm_train)
#[1] 24951

movies_dtm_freq_train <- movies_dtm_train[ , movies_freq_words]
movies_dtm_freq_test <- movies_dtm_test[ , movies_freq_words]

ncol(movies_dtm_freq_train)
#[1] 1027
```


Finalmente, ya que las matrices DTM tienen valores numéricos, mientras que el algoritmo de clasificación basado en naive bayes necesita operar sobre variables categóricas, se necesita realizar una última tranformación: pasar los valores numéricos a Sí/No:

```{r}
#We need a function that converts counts to a factor
convert_counts <- function(x) {
  x <- ifelse(x > 0, "Pos", "Neg")
}
#and we apply it
movies_train <- apply(movies_dtm_freq_train, MARGIN = 2, convert_counts)  # MARGIN = 2 <- columns
movies_test <- apply(movies_dtm_freq_test, MARGIN = 2, convert_counts)
# The result will be two matrices, each with cells indicating "Yes" or "No" for whether
# the word represented by the column appears at any point in the message represented by the row.
```


## Uso de caret para mejorar el modelo

Para comprobar qué parámetros pueden ser ajustados:

```{r}
modelLookup("naive_bayes")
```

Control:

```{r}
ctrl <- trainControl(method = "cv", number = 10, selectionFunction = "best")  #repeats = 10, 
```


Entrenamiento 1:

Dado que se trata de un dataset balanceado, vamos a usar la métrica exactitud en lugar de Kappa.

```{r}
set.seed(12345)

system.time({
  m <- train(class ~ ., data = movies_train, 
             method = "naive_bayes",
             metric = "Accuracy",
             #usepoisson = TRUE,
             trControl = ctrl)
})
```


```{r}
m
```

Me llama mucho la atención que el valor de la exactitud es muy muy alto, mientras que el de Kappa es 0 ..
(He probado varias combinaciones, con el mismo resultado).


```{r}
plot(m)
```


Entrenamiento 2:

Creamos una rejilla/matriz de parámetros alrededor de los parámetros encontrados de manera automática por caret:

```{r}
grid <- expand.grid(laplace = c(0, 0.5, 1.0),
                    usekernel = c(FALSE, TRUE),
                    adjust = c(0.5, 0.75, 1, 1.25))

grid
```

```{r}
#set.seed(12345)
#
#system.time({
#  m_nb <- train(class ~ ., data = dtm, 
#             method = "nb",
#             metric = "Accuracy",
#             trControl = ctrl,
#             tuneGrid = grid)
#})
```
Output:

Error: protect(): protección del desborde de la pila
Timing stopped at: 95.97 0.723 96.43

!!!?


```{r}
set.seed(12345)

system.time({
  m <- train(class ~ ., data = movies_train, 
             method = "naive_bayes",
             metric = "Accuracy",
             usepoisson = TRUE,
             trControl = ctrl,
             tuneGrid = grid)
})
```


```{r}
m
```
El parámetro que verdaderamente influye es "usekernel". Si "userkernel" es TRUE (y FALSE), 
los valores de laplace y de "adjust" no influyen, se obtiene la misma exactitud y Kappa.

  0        FALSE      1.25  **0.6786667  0.06693412**
  0         TRUE      0.50  **0.9133333  0.00000000**
  
  O exactitud 0.913 y kappa 0, o exactitud 0.678 y kappa 0.669

```{r}
plot(m)
```


```{r}
#m$finalModel
```


Predicción:

```{r}
movies_pred <- predict(m, movies_test)
movies_pred
```


Resultado:

```{r}
#confusion matrix
confusionMatrix(reference = movies_test_labels, data = movies_pred, mode = "everything", positive = "Pos")
```

Se obtiene un resultado ... absurdo, con los parámetros que devuelve caret.


Si forzamos kernel FALSE:


```{r}
grid2 <- expand.grid(laplace = c(0, 1.0),
                    usekernel = c(FALSE),
                    adjust = c(0.75, 1, 1.25))

grid2
```


```{r}
set.seed(12345)

system.time({
  m2 <- train(class ~ ., data = movies_train, method = "naive_bayes",
            metric = "Accuracy",
            usepoisson = TRUE,
            trControl = ctrl,
            tuneGrid = grid2)
})
```


```{r}
m2
```

Predicción:

```{r}
movies_pred2 <- predict(m2, movies_test)
movies_pred2
```


Resultado:

```{r}
#confusion matrix
confusionMatrix(reference = movies_test_labels, data = movies_pred2, mode = "everything", positive = "Pos")
```

Se obtiene un resultado peor que en la tarea del tema 4.

Si el procesado de los textos estuviera erróneo, al aplicar naive bayes de igual manera que en ejercicio 4
se obtendría un resultado también peor. Pero se obtiene exactamente lo mismo:

**Tema 4:**

```{r}
system.time({
  movies_classifier_tema4 <- naive_bayes(movies_train, movies_train_labels)
})
#movies_classifier_tema4
```


```{r}
#predict
system.time({
  movies_test_pred_tema4 <- predict(movies_classifier_tema4, movies_test)
})
```

```{r}
#confusion matrix
confusionMatrix(reference = movies_test_labels, data = movies_test_pred_tema4, mode = "everything", positive = "Pos")
```


