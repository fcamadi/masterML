---
title: "Tema4_Ejercicio"
author: "Fran Camacho"
date: "2025-01-15"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = TRUE)
```

# Tema4 - Ejercicio

El fichero “movie-pang02.csv”, disponible en la carpeta de Pruebas de Evaluación del Máster, contiene una muestra de 2000 críticas de películas de
la página web IMDB utilizada en el artículo de Pang, B. y Lee, L., "A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on
Minimum Cuts, Proceedings of ACL 2004". 

Dichas críticas están etiquetadas mediante la variable class como positivas (“Pos”) o negativas (“Neg”).
Utilizando dicho dataset, elabore un modelo de clasificación de reviews en base a su texto siguiendo el procedimiento descrito en el capítulo 4 del texto base
en el ejemplo de SMS Spam. En particular, genere las nubes de palabras para las reviews positivas y negativas, y obtenga el modelo asignando los valores 0
y 1 al parámetro laplace de la función naiveBayes(), comparando las matrices de confusión de cada variante del modelo.

## Paso 1: Carga de los datos

```{r}
# import the CSV file
movies_raw <- read.csv(file.path("Chapter04", "Movie_pang02.csv"))
```


## Paso 2: Explorar y preparar los datos


Carga de paquetes que son necesarios para diversas funciones.

```{r}
if (!require(tm)) install.packages('tm', dependencies = T)   # text mining
library(tm)

if (!require(SnowballC)) install.packages('SnowballC', dependencies = T)   # stemming
library(SnowballC)

if (!require(wordcloud)) install.packages('wordcloud', dependencies = T)   # wordclouds
library(wordcloud)

if (!require(RColorBrewer)) install.packages('RColorBrewer', dependencies = T)   # color palettes
library(RColorBrewer)

if (!require(naivebayes)) install.packages('naivebayes', dependencies = T)
library(naivebayes)

if (!require(caret)) install.packages('caret', dependencies = T)   # data partitioning, confusion matrix
library(caret)         
```


Examinamos la estructura y el aspecto del fichero importado:

```{r}
#See the structure
str(movies_raw)
```


```{r}
#See some records
#head(movies_raw)  #omitted for brevity
```
```{r}
#See some records
#tail(movies_raw)  #omitted for brevity
```

La columna "class" es de tipo carácter. Ya que se trata en realidad de una variable categórica, es conveniente transformarla en un factor:

```{r}
#Convert class into a factor
movies_raw$class <- factor(movies_raw$class)
```

Y examinamos el resultado

```{r}
table(movies_raw$class)
```

Vemos que hay tantas críticas positivas como negativas.


### Procesado del texto de las críticas

Procedemos ahora a preparar el fichero para que pueda ser procesado mediante el algoritmo Naive Bayes:
Hay que eliminar mayúsculas y signos de puntuación, números, realizar la lematización ("stemming" en inglés) ...

El primer paso consiste en la creación del objeto corpus con todas las críticas:

```{r}
#create corpus
movies_corpus <- VCorpus(VectorSource(movies_raw$text))
print(movies_corpus)
#inspect(movies_corpus) omitted for brevity
```

```{r}
# examine the movies corpus
# lapply(movies_corpus[1:5], as.character)
# we omit the output for brevity
```

Limpieza de los textos:

```{r}
system.time({
# Process the reviews (we will use some functions from the packate tm)

#To lowercase (content seems to be already in lowercase and without punctuation signs, but just in case)
movies_corpus_clean <- tm_map(movies_corpus, content_transformer(tolower))

#Check the result (output omitted for brevity)
#as.character(movies_corpus[[1]])
#as.character(movies_corpus_clean[[1]])

#Remove numbers
movies_corpus_clean <- tm_map(movies_corpus_clean, removeNumbers)

#Remove stopwords
# check words and languages with ?stopwords
movies_corpus_clean <- tm_map(movies_corpus_clean, removeWords, stopwords()) 
#Remove punctuation signs
movies_corpus_clean <- tm_map(movies_corpus_clean, removePunctuation) 


#Carry out the stemming:
# To apply the wordStem() function to an entire corpus of text documents, the tm package includes
# the stemDocument() transformation.
movies_corpus_clean <- tm_map(movies_corpus_clean, stemDocument)

#Finally eliminate unneeded whitespace produced by previous steps
movies_corpus_clean <- tm_map(movies_corpus_clean, stripWhitespace) 

#Check the final result (output omitted for brevity)
#before cleaning
#as.character(movies_corpus[[1]])
#after
#as.character(movies_corpus_clean[[1]])
})
```

Finalmente, se procede a la **"tokenización"** de los textos de las críticas.

Mediante la función DocumentTermMatrix() del paquete "tm", se crea una estructura llamada "document-term matrix (DTM)",
que como su nombre indica es una matriz, cuyas filas consisten en los textos(documentos) y cuyas columnas son las palabras que aparecen en esos documentos.
Los valores en cada celda son el número de ocurrencias de cada palabra en cada documento.

```{r}
movies_dtm <- DocumentTermMatrix(movies_corpus_clean)
movies_dtm
```

[Tenemos 2000 documentos, y 24951 palabras].

Ahora hay que crear los conjuntos de entrenamiento y de test.
Las críticas vienen ordenadas, primero las 1000 críticas positivas, y después las 1000 críticas negativas.
Por tanto hay que crear estos dos conjuntos de manera aleatoria.

```{r}
#Set seed to make the process reproducible
set.seed(8)

#partitioning data frame into training (75%) and testing (25%) sets
train_indices <- createDataPartition(movies_raw$class, times=1, p=.75, list=FALSE)

#create training set
movies_dtm_train <- movies_dtm[train_indices, ]

#create testing set
movies_dtm_test  <- movies_dtm[-train_indices, ]

#create labels sets
movies_train_labels <- movies_raw[train_indices, ]$class
movies_test_labels <- movies_raw[-train_indices, ]$class

#view number of rows in each set
#nrow(movies_dtm_train)  # 1500
#nrow(movies_dtm_test)   # 500
#length(movies_train_labels)  # 1500
#length(movies_test_labels)   # 500
```

Vamos a comprobar ahora que los dos conjuntos tienen la misma proporción de críticas positivas y negativas (si no, el entrenamiento no serviría para nada):

```{r}
prop.table(table(movies_train_labels))
prop.table(table(movies_test_labels))
```

La proporción se mantiene en los dos conjuntos.

### Visualización mediante nubes de palabras (wordclouds)

Se puede obtener una nube con las palabras de todas las críticas, y también una nube para las críticas positivas y otra para las negativas.

Total de críticas:

```{r}
wordcloud(movies_raw$tex, min.freq = 50, random.order = FALSE)
```

```{r}
#Using the corpus:
#wordcloud(movies_corpus_clean, min.freq = 50, random.order = FALSE)
```

```{r}
#Using the corpus with color:
wordcloud(movies_corpus_clean, min.freq = 50, random.order = FALSE, colors=brewer.pal(8,"Dark2"))
```


Críticas positivas y críticas negativas por separado:

```{r}
pos <- subset(movies_raw, class == "Pos")
neg <- subset(movies_raw, class == "Neg")

wordcloud(pos$text, max.words = 50, random.order = FALSE, colors=brewer.pal(8,"Dark2"))
wordcloud(neg$text, max.words = 50, random.order = FALSE, colors=brewer.pal(8,"Dark2"))

#wordcloud(pos$text, max.words = 50, scale = c(3, 0.5), random.order = FALSE)
#wordcloud(neg$text, max.words = 50, scale = c(3, 0.5), random.order = FALSE)
```
La única diferencia que aprecio entre las dos nubes, es que en la nube negativa se encuentra la palabra "bad" (también "never").
Palabras positivas como "good", like", "well", aparecen en las 2 agrupaciones.
("like" es también una preposición/conjunción, no tiene solo el significado de "gustar").


###Finalizamos ahora la preparación de los datos

Se necesita obtener un listado con las palabras más utilizadas:

```{r}
# Data preparation – creating indicator features for frequent words
# the function findFreqTerms() in the tm package takes a DTM and returns a character vector containing words that appear at least a  minimum number of times
movies_freq_words <- findFreqTerms(movies_dtm_train, 100)

movies_freq_words
```

   [1] "abil"         "abl"          "absolut"      "accept"       "achiev"       "across"       "act"          "action"       "actor"        "actress"     
  [11] "actual"       "adam"         "adapt"        "add"          "addit"        "admit"        "adult"        "adventur"     "age"          "agent"       
  [21] "ago"          "agre"         "air"          "alien"        "allen"        "allow"        "almost"       "alon"         "along"        "alreadi"     
  [31] "also"         "although"     "alway"        "amaz"         "america"      "american"     "among"        "amount"       "amus"         "angel"       
  ...
 [501] "lead"         "leader"       "learn"        "least"        "leav"         "lee"          "left"         "legend"       "less"         "let"         
 [511] "level"        "lie"          "life"         "light"        "like"         "limit"        "line"         "list"         "liter"        "littl"       
 [521] "live"         "local"        "long"         "longer"       "look"         "lose"         "lost"         "lot"          "loud"         "love"        
 [531] "lover"        "low"          "machin"       "made"         "magic"        "main"         "major"        "make"         "man"          "manag"     
  ...
 [971] "virtual"      "visual"       "voic"         "wait"         "walk"         "want"         "war"          "warn"         "wasn"         "wast"        
 [981] "watch"        "water"        "way"          "weak"         "wear"         "wed"          "week"         "well"         "went"         "west"        
 [991] "whatev"       "whether"      "white"        "whole"        "whose"        "wife"         "wild"         "will"         "willi"        "william"   
 
 [ reached getOption("max.print") -- omitted 27 entries ]
 
 
Y ahora utilizamos ese listado para limitar el número de columnas/features de los conjuntos de entrenamiento y de test:

```{r}
#> ncol(movies_dtm_train)
#[1] 24951
movies_dtm_freq_train <- movies_dtm_train[ , movies_freq_words]
movies_dtm_freq_test <- movies_dtm_test[ , movies_freq_words]
#> ncol(movies_dtm_freq_train)
#[1] 1027
```

Ahora los conjuntos de entrenamiento y test tienen 1027 columnas/features, en lugar de 24951.

Finalmente, ya que las matrices DTM tienen valores numéricos, mientras que el algoritmo de clasificación basado en naive bayes necesita operar sobre variables categóricas, se necesita realizar una última tranformación: pasar los valores numéricos a Sí/No:

```{r}
#We need a function that converts counts to a factor
convert_counts <- function(x) {
  x <- ifelse(x > 0, "Yes", "No")
}
#and we apply it
movies_train <- apply(movies_dtm_freq_train, MARGIN = 2, convert_counts)  # MARGIN = 2 <- columns
movies_test <- apply(movies_dtm_freq_test, MARGIN = 2, convert_counts)
# The result will be two matrices, each with cells indicating "Yes" or "No" for whether
# the word represented by the column appears at any point in the message represented by the row.
```


## Paso 3: Entrenamiento del modelo

```{r}
system.time({
  movies_classifier <- naive_bayes(movies_train, movies_train_labels)
})
movies_classifier
```

## Paso 4: Evaluación del modelo

Realizamos la predicción

```{r}
#predict
system.time({
  movies_test_pred <- predict(movies_classifier, movies_test)
})
```

Y comparamos lo predicho por el algoritmo con los datos etiquetados anteriormente

```{r}
#confusion matrix
confusionMatrix(reference = movies_test_labels, data = movies_test_pred, mode = "everything", positive = "Pos")
```

Como ya sospechaba, al no haber diferencias tan evidentes entre las nubes de palabras de las críticas positivas y negativas como en las nubes del ejercicio del libro sobre el spam de los mensajes SMS, el resultado no es tan expectacular como en ese otro caso. Al algoritmo Naive Bayes le cuesta más predecir correctamente.

**Exactitud** (**"accuracy"**):

    TP + TN / TP + FP + TN + FN (total) = 191 + 207 / 191 + 43 + 207 + 59  = 191 + 207 / 500 = 0.796 

Es decir, los clasificados correctamente sobre el total.


**Precisión**

Proporción de de positivos reales del total devuelto:

Precision = TP / TP + FP = 191 / 191 + 43 = 0.8162 


**Recall** (Recuperación, o Tasa de verdaderos positivos (TPR))

Proporción de todos los positivos reales que se clasificaron correctamente como positivos, también se conoce como recuperación.

Recall = TP / TP + FN = 191 / 191 + 59 = 0.7640

**F1 score** (Puntuación F1)

La puntuación F1 es la media armónica (un tipo de promedio) de la precisión y la recuperación.
Se obtiene de la siguiente manera:

F1 = 2 x (precision x recall) / (precision + recall) = 2TP / 2TP + FP + FN = 0.7893


## Paso 5: Mejora del modelo

Configuramos el estimador de Laplace (parametro "Laplace smoothing") con el valor 1. De esta manera se evita que las palabras que solo aparecen en uno de los 2 conjuntos (entrenamiento o tes), empeoren el resultado total.

```{r}
#  laplace = 1
system.time({
  movies_classifier_laplace <- naive_bayes(movies_train, movies_train_labels, laplace = 1)
})
movies_classifier_laplace
```

Volvemos a ejecutar el algoritmo

```{r}
#predict
system.time({
  movies_test_pred_laplace <- predict(movies_classifier_laplace, movies_test)
})
```

Y volvemos a comparar lo predicho por el algoritmo con los datos etiquetados

```{r}
#confusion matrix
confusionMatrix(reference = movies_test_labels, data = movies_test_pred_laplace, mode = "everything", positive = "Pos")
```

Para mí sorpresa, el resultado es peor: ahora se han clasificado 2 críticas positivas más de manera errónea como negativas.


Dado que el resultado no ha sido todo lo positivo que esperábamos, vamos a utilizar el clasificador naive bayes multinomial (MNB), en lugar del anterior (bernoulli).


### Paso 5.1: Utilización de la versión multinomial del algoritmo Naive Bayes

Entrenamiento del modelo:

```{r}
#model training with laplace = 0
system.time({
  movies_classifier_mnb <- multinomial_naive_bayes(movies_dtm_freq_train, movies_train_labels, laplace = 0)
})
movies_classifier_mnb
```

Ejecución/predicción:

Al llamar al método predict directamente con la dtm de test, a diferencia del paso anterior (entrenamiento), da un error.

```{r}
# predict
#movies_dtm_freq_test
#inspect(movies_dtm_freq_test[1:10,1:10])
#    Terms
#Docs abil abl absolut accept achiev across act action actor actress
#  10    0   0       0      0      0      0   0      4     0       0
#  12    1   0       0      0      0      0   0      0     1       0
#  18    0   0       0      0      0      0   4      4     2       0
# ...
#movies_test_pred_mnb <- predict(movies_classifier_mnb, newdata = movies_matrix_freq_test, type='class')
# It returns
# Error: predict.multinomial_naive_bayes(): newdata must be a numeric matrix or dgCMatrix (Matrix package) with at least one row and two named columns.
```

Así que convertimos la dtm de test en una matriz, y ahora sí obtenemos la predicción:

```{r}
#So I try again transforming the dtm into a matrix
system.time({
  movies_test_pred_mnb <- predict(movies_classifier_mnb, newdata = as.matrix(movies_dtm_freq_test), type='class')
})
#movies_test_pred_mnb
#  [1] Neg Neg Pos Pos Pos Pos Pos Pos Neg Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Neg Neg Pos Pos Pos Neg Pos Neg Pos Pos Pos Neg Pos Neg Pos Pos Pos Pos
# [40] Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Neg Neg Pos Pos Pos Neg Pos Neg Pos Neg Pos Pos Pos Pos Pos Neg Pos Pos Neg Pos Pos Pos Pos Pos Pos
#...
```


```{r}
# Converting to a dgCMatrix also works
#movies_dgCMatrix_freq_test <-  Matrix::sparseMatrix(i=movies_dtm_freq_test$i, 
#                           j=movies_dtm_freq_test$j, 
#                           x=movies_dtm_freq_test$v, 
#                           dims=c(movies_dtm_freq_test$nrow, movies_dtm_freq_test$ncol),
#                           dimnames = movies_dtm_freq_test$dimnames)
#movies_dgCMatrix_freq_test
# 500 x 1027 sparse Matrix of class "dgCMatrix"
#                                                                                                                                                            
#2  . . . . 1 . . . . . . . . 1 . . 2 . . . . . . . . . . . 1 . . . . . . . . 1 .  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ......
#5  . . . . . 2 . . 1 . . . . . . . . . . 1 . . . . 1 . 1 . . . 1 . 1 . . . . . .  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 2 ......
#...
#movies_test_pred_mnb <- predict(movies_classifier_mnb, newdata = movies_dgCMatrix_freq_test, type='class')
```

Volvemos a comparar lo predicho por el algoritmo con los datos etiquetados

```{r}
#confusion matrix
confusionMatrix(reference = movies_test_labels, data = movies_test_pred_mnb, mode = "everything", positive = "Pos")
```

```{r}
#model training with laplace = 1
system.time({
  movies_classifier_mnb_laplace <- multinomial_naive_bayes(movies_dtm_freq_train, movies_train_labels, laplace = 1)
})
movies_classifier_mnb_laplace
```
```{r}
#prediction
system.time({
  movies_test_pred_mnb_laplace <- predict(movies_classifier_mnb_laplace, newdata = as.matrix(movies_dtm_freq_test), type='class')
})
```


```{r}
#confusion matrix
confusionMatrix(reference = movies_test_labels, data = movies_test_pred_mnb_laplace, mode = "everything", positive = "Pos")
```

