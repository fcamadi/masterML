---
title: "Keras_Example"
author: "Fran Camacho"
date: "2025-03-03"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Tomado de:

https://fritz.ai/binary-classification-using-keras-in-r/


Carga de paquetes que son necesarios para diversas funciones.

```{r}

#if (!require(keras3)) install.packages('keras3', dependencies = T)
library(keras3)
#install_keras()

```

```{r}

if (!require(tidyverse)) install.packages('tidyverse', dependencies = T)
library(tidyverse)

if (!require(fastDummies)) install.packages('fastDummies', dependencies = T)
library(fastDummies)

if (!require(caret)) install.packages('caret', dependencies = T)
library(caret)   

if (!require(ggplot2)) install.packages('ggplot2', dependencies = T)
library(ggplot2)

```



```{r}

# import the CSV file
df <- read.csv(file.path("Chapter07", "kyphosis.csv"), stringsAsFactors = TRUE)

```


```{r}
#See the structure
str(df)
```


```{r}
#Summary
summary(df)
```


```{r}
#some registers
head(df)
```



```{r}
#transform categorical feature
dummy_data <- fastDummies::dummy_cols(df,remove_first_dummy = TRUE)

head(dummy_data)   
```

```{r}
#Remove original target variable
keep <- c('Age','Number','Start','Kyphosis_present')
final <- dummy_data[keep]

head(final) 
```


```{r}
index <- createDataPartition(final$Kyphosis_present, p=0.7, list=FALSE)
```


```{r}
final.training <- final[index,]
final.test <- final[-index,]
```


```{r}
#
X_train <- final.training %>% 
  select(-Kyphosis_present) %>% 
  scale()
  
y_train <- keras3::to_categorical(final.training$Kyphosis_present)
```

Create training and test sets

```{r}
X_test <- final.test %>% 
  select(-Kyphosis_present) %>% 
  scale()

y_test <- keras3::to_categorical(final.test$Kyphosis_present)
```


```{r}
#
typeof(X_train)
typeof(y_train)
typeof(X_test)
typeof(y_test)
```


## Build Keras model:


```{r}
model <- keras_model_sequential(name = "keras_1") 

model %>% 
  layer_dense(name = "dense_1", units = 256, activation = 'relu', input_shape = ncol(X_train)) %>% 
  layer_dropout(name = "dropout_2", rate = 0.4) %>% 
  layer_dense(name = "dense_3", units = 128, activation = 'relu') %>%
  layer_dropout(name = "dropout_4", rate = 0.3) %>%
  layer_dense(name = "dense_5", units = 2, activation = 'sigmoid')

model <- model %>% compile(
  loss = 'binary_crossentropy',
  optimizer = 'adam',
  metrics = c('accuracy')
)
```


```{r}
  model
  #plot(model)
```

## Train model

```{r}
model %>% fit(
  X_train, y_train, 
  epochs = 100, 
  batch_size = 5,
  validation_split = 0.3
)
```

## Evaluate model:

```{r}
model %>% evaluate(X_test, y_test)
```

With epoch=100 :

1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.8333 - loss: 0.9819
$accuracy
[1] 0.8333333

$loss
[1] 0.9818876




```{r}
plot(model$metrics$loss, main="Model Loss", xlab = "epoch", ylab="loss", col="orange", type="l")

lines(model$metrics$val_loss, col="skyblue")

legend("topright", c("Training","Testing"), col=c("orange", "skyblue"), lty=c(1,1))
```






```{r}
plot(history$metrics$acc, main="Model Accuracy", xlab = "epoch", ylab="accuracy", col="orange", type="l")

lines(history$metrics$val_acc, col="skyblue")

legend("topleft", c("Training","Testing"), col=c("orange", "skyblue"), lty=c(1,1))
```



